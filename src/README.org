* ERD/WORM dirty speech synth

32k sample rate->48k?

*we always need transition from previous phoneme for each mode (inc X/Y)!* - this can also be faked/transition in phoneme itself

* TODO:

- generate - wrapper and structure and pointer to function calls...

- clear naming scheme eg. for nvp algo:

init_nvp(void)

generate_nvp(generator* nvp_generator, u16 size, int16_t* incoming, int16_t* outgoing)

or:

generate[x]->pointer to nvp and also generic struct to keep track of frames and so on...

(but generator* should be void and cast)

- satisfactory vocoder

- re-think how all works with excitation and resonance/process - what
  models don't work in this way (more classical speech synth), and
  how that could work with vocoder - how we can vary excitation such
  as white noise. list excitations

- wormings algorithms. control over degree of randomness of movements

* modes

*MODE | IS? | FILES/DIR | BASED_ON | NOTES/TODO - to add to TODO from below*

0-   | klatt single phoneme | klatt in rsynth | rsynth-2.0-port | single phoneme needs transition always to make sense

but this can be done with transition/pitch etc. in each phoneme - what
are these changing elements - write to parfile... make thus larger phoneme list

collate klatt/holmes notes below which also mention this!

again how long is each frame, how many frames per phoneme, how to
simplify figuring out transitions and also calls to init...

//at 32000 samples per sec 10ms=320 samples - in def_pars.c we have 8ms per frame = 256 samples//

1-   | klatt chain of phonemes | klatt |rsynth-2.0-port | 

klatt always needs next phoneme so what to do if no next is signalled
(repeat or loop through list as determined)?

also updating klatt phoneme might cause glitch in audio if we do it in
audio.c // so larger/main buffer=special case perhaps as mode 0

- this becomes two modes: cycling phonemes and simplified klatt//wormed klatt

2-   | SC-VOSIM | vosim.c | SC | one of these is free running???
3-   | SC-VOSIM? | vosim.c  | SC | 
4-   | MDA_VOCODER | mdavoc.c | MDA? | excitation is also there? 
5-   | LADSPA VOCODER | vocode.c | ladspa | 
6-   | SELX/Y FILTERS |  | | choose/check which bandpass DROP!
7-   | doformantfilter-few vowels | effect.c | none | try different bandpass/move between vowels/more formants 
8-   | formlet | effect.c | SC | 
9-   | SAM | sam.c | sam.c??? |
10-  | LPC/Talkie | LPC/lpc.c  | talkie |  larger vocabulary  // = TMS5220

add vocab from: [[file:~/projects/ERD_modules/older/euro-modules/Talko/Software/TalkoVCO/TalkoVCO.ino]] DONE

have speed of samples change!

from where else? arcade games/roms

compare Talkie to LPC to MAME code which is: [[file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/tms5220.c::TMS5200/5220%20simulator][file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/tms5220.c::TMS5200/5220 simulator]]

(also pd tms code)

calculating:

http://www.angelfire.com/electronic2/speechproject/speech_param.htm

- using encoder - calc.m and romgen from talkie with freemat and online convertor - use 8 KHz 16 bit mono recordings to encode words for lpc.c

see also: http://www.vectorlist.org/Vectorlist/2012/05/0062.html, unianal (bit not for TMS5220), qboxpro doesn't run on our WINE

http://www.polaxis.be/category/talkie/

https://github.com/going-digital/Talkie/issues/4

https://github.com/going-digital/Talkie/issues/6 - question of speed/sample speed... and voice/settings

http://www.stefan-uhlmann.de/cbm/MVM/Magictalkie/

11-  | SC formant | scformant.c  | SC | is sine working properly? 
12-  | borboom vocoder | vocoder/vocode.c | borboom | try with ARM FFT - do we serial conn. to check FFT?
13-  | rendervosim | braidworm.c | braids - [[file:~/projects/ERD_modules/older/eurorack/braids/digital_oscillator.cc]] | needs worming not to use straight 
14-  | rendervowel | braidworm.c | braids | 
15-  | rendervowelfof | braidworm.c | braids | 
16-  | lpcanalyzer | lpcanalysiss.c  | SC | 

Linear predictive coding analysis on any arbitrary input signal. The
spectrum of the input signal is modeled, and used to filter the
source. This works most successfully if the source is spectrally flat
to begin with, ie, an impulse train ( Impulse UGen ) or white noise (
WhiteNoise UGen ).

- need more exciters...

17-  | voicform | voicform.c  | STK | 
18-  | tubesim | tube.c | TRM | 
---in progress
19-  | simpleklatt | simpleklatt.c | klatt | 
20-  | nvp | nvp.c | nv speechplayer | klatt also |

but we still need to test this or?

////
towards maximum 32 modes! cut vocoders to basic/working with swopped excitation/voice input

cut other modes to focus on:

- TRM/tubes
- Klatt
- LPC
- vocoder

** klatt notes

*** working through rsynth-2.0 5/1/2016

- "eh" is 18 frames = 180 mS (we have this with silence)...

double mSec_per_frame = 10; 8000 is sample rate...

- holmes is where frames are interpolated from phonemes/element list:

nEparm is number of parameters in each frame

holmes runs  parwave_init(&klatt_global) and        parwave(&klatt_global, &pars, samp) for each frame...

parwave in nsynth.c ->    CONVERT FRAME OF PARAMETER DATA TO A WAVEFORM CHUNK

for our single phonemes in code HERE we run:
PhonemeToWaveData(phoneme,1, 0) -> say.c which is trimmed to take
phoneme code and then run:

wav_len = holmes(3, intern,max_samples, pWavBuffer	);

which brings us back into single phoneme/transition issue - as will
always transition to Q then END and both are null

- what is first line of Elements.def for each phoneme eg...: {"DZ",  26, 1, 1,0x64,"d","d",alv|stp|vcd, ->

typedef struct Elm_s
 {
  char *name;
  char rk; - dominance of element
  char du; - dur/
  char ud; - dur/
  unsigned char font; ???
  char  *dict;
  char  *ipa;
  long  feat;
  interp_t p[nEparm];
 } Elm_t, *Elm_ptr;

and then each parameter has list

 {float stdy;
  float fixd;
  char  prop;
  char  ed;
  char  id;

- stdy, fixd, prop// used for transitions /// ed=, id= ext or int times???

- duration is 6 for example: ./say "eh" -v -l test.raw -p test.par - so 6 frames for E,Q-null,END-null

- how would it sound if we have no transitions - klatt and pyklatt/klsyn: -> simpler klatt without interpolation

- see klsyn (restrictions on commercial use) also for synthesis from
  base parameters - also new parameters - to test this out but seems bit cumbersome...

- for klatt we use: ./klatt -i example1.par -r 2 -s 8000 -o test.raw and:

 play -t raw --bits 16 --channels 1 --encoding signed-integer --rate 8000 test.raw

with examples as list of parameters 

figure out also how klatts and online parwave.c differ from local klatt // latest rsynth also

http://show.docjava.com/book/cgij/code/data/lectures/cr310/DSP/chapter%205/711/klatt/parwave.c

http://homepages.wmich.edu/~hillenbr/klsyn/klsyn.txt

- nvp.c half through porting is also a much simpler klatt... tho ipa.py makes it a bit more complex

*** what are global varyings for klatt:

- from command line options: flutter, base F0, tilt db, msec per
  frame, number of formants in cascade - but default is parallel, impulse glottal source bool // holmes =
  -S <d> [1] Speed (1.0 is 'normal') -K <lg> [1] Parameter filter
  'fraction'

- for example we can vary base (as top in holmes) dynamically, also values like duration we can alter

- in rsynth: def_pars.c (what is pars.def for? - is default frame definition)

long samp_rate = 32000;

void init_synth(void)
{
	//double mSec_per_frame = 10;
  float mSec_per_frame = 8; // 10?
	//int impulse = 0;
	int impulse = 1;
	//int casc = 1;
	int casc = 2;
	klatt_global.samrate = samp_rate;
	klatt_global.quiet_flag = TRUE;
	klatt_global.glsource = NATURAL;// IMPULSIVE doesn't work - but is set below!
	klatt_global.f0_flutter = 0;

	//	klatt_global.quiet_flag, "Quiet - minimal messages",
	//	impulse,                 "Impulse glottal source",
	//	casc,                    "Number cascade formants",
	//	klatt_global.f0_flutter, "F0 flutter",
	//	mSec_per_frame,         "mSec per frame",
	//	def_pars.TLTdb,          "Tilt dB",
	//	def_pars.F0hz10,         "Base F0 in 0.1Hz",

	if (casc > 0)
	{
		klatt_global.synthesis_model = CASCADE_PARALLEL;
		klatt_global.nfcascade = casc;
	}
	else
		klatt_global.synthesis_model = ALL_PARALLEL;

	if (impulse)
		klatt_global.glsource = IMPULSIVE;

	klatt_global.nspfr = (klatt_global.samrate * mSec_per_frame) / 1000;
}

- and rsynth in docs:

 double mSec_per_frame = 10;
 int impulse = 0;
 int casc = 0;
 klatt_global.samrate = samp_rate;
 klatt_global.quiet_flag = TRUE;
 klatt_global.glsource = NATURAL;
 klatt_global.f0_flutter = 0;

- NATURAL changes impulses but in doc/klatt code we have natural
  sampled source - but doesn't work - option is 2 - fixed as SAMPLE_FACTOR was very small - mult * 2.0

*** other notes

- in mage video - wheel for repeating phoneme loop selection to maybe implement // how this could work?

- so klatt mode should just be that looping and maybe a stripped or
  reduced klatt without transitions as a seperate mode with more changes in pitch and so on

- TODO: nvp.c port - ipa.py questions, test generation of klsyn/klatt
  parameters from simple code, does rsynth sound same on worm or do we
  have samplerate issues - play also with various defines (see above)DONE/// port that simple klatt

example1.par: 40 params

1000 0 543 0 1324 0 2663 0 3681 0 4279 0 4000 0 0 0 200 40  0 40  0 20  0  0  0 52  0 57  0 72  0 67  0 80  0 80  0  0  0 70

// see genparam.c - what are important ones, how they depend on each other esp. F0 and nopen/T0 timings:

    /* T0 is 4* the number of samples in one pitch period */

    globals->T0 = (40 * globals->samrate) / frame->F0hz10;

and nopen (=4x Kopen in the frame) cannot be > T0

// in our test case samrate is 8000 so x40=320,000 / F0hz which starts at 1000 = less than 320 /4 for kopen=80

also case with Kskew to figure out... so need to implement these constraints

*** collated from below TODO

** own speech synth: worm.c

- also what are differences between chips such as sp0256/votrax - (see patents)

Following klatt:

- excitation - voiced/unvoiced, changes in frequency of glottal pulses, white noise...
- filtering - formants and zero poles (nasal), any tube modelling,
  open and close of mouth - see latest book

* worming

- wormbounds x/y exerted on parameters + speed of worming z?
- worm trigger?

* desc/manual

The WORM was for a long time desirous to speake, but the rule and
orâˆ£der of the Court enjoyned him silence, but now strutting and
swelling, and impatient, of further delay, he broke out thus... [Maier]

http://quod.lib.umich.edu/e/eebo/A51439.0001.001/1:3.6?rgn=div2;view=fulltext

In contrast to other speech modules which make use of a single speech
chip or algorithm ERD/WORM implements multiple speech codecs...

for cv and knobs - as above so below.... mirroring...


* discard

csound fof= http://www.csounds.com/manual/html/fof.html - ugens7.c

[1. phase vocoder/FFT - our old pitchscale.c??? 

JoshUGens/sc/classes/Vocoder.sc

SCcode=PV_SpectralMap, borsboom, snokoder]

runform in simforstacksansmem 

- what effects we implement in DI: mdavoc, pvvoc
  


* using SC notes

http://swiki.hfbk-hamburg.de/MusicTechnology/848.diff?id=30

M-x sclang-start
M-x sclang-server-boot
(C-x C-e eval)
C-c C-s STOP!

C-c C-c eval line or region

C-c C-h searches for a help file 
C-M-h switches to the Help browser 

E copies the buffer, puts it in text mode and sclang-minor-mode, to
enable you to edit the code parts to try out variations of the
provided code in the help file. With C-M-h you can then return to the
Help browser and browse further from the Help file.

putting sc class files in /usr/local/share/SuperCollider/Extensions

** problems

problem is help only seems to access html and not schelp????

stk stuff doesn't work

** snippets

x = Synth(\voicform);
x.set(\sweepRate, 0.5);
i=0;

(
    i = i+1;
    a = Phonemes.parameter(i).flop;
    b = Phonemes.gain(i);
    Phonemes.string(i).postln;
    x.setn(\ffreq, a[0]);
    x.setn(\bw, 1-a[1]);
    x.setn(\gain, a[2].dbamp);
    x.set(\voiceGain, b[0]);
    x.set(\noiseGain, b[1]);
    x.set(\freq, exprand(200, 800) );
)

x.play;


*  Matlab/octave notes

use wavwrite but always problems with:

error: wavwrite: Y has more than 32767 columns (too many for a WAV-file)


* TODO OLD!!!!

- sort out memory allocationsDONE
- basics of read/write head and speech integrationDONE
- tests for each speech function/mode
- vocoder 
- integrate/test/new knob allocations when we have PCB DONE

...///
- port all speech algos 
////
- wormcode and klatt parameter limits
- inverse filter/LPC??? for klatt
- phoneme probabilities DONE
- run_holmes see below

* knobs

#define MODE 3 // for pcb=2
#define SELX 0 //3
#define SPEED 2 //0
#define SELZ/END 4 //4
#define SELY 1 //1


* modes so far imagined - say 32 total!

0/klatt - single phoneme
0.1/klatt - list of phonemes
0.2/klatt - worm away starting on phoneme base (earth worm) - or trigger that base
1/vosim 
2/x-y filter 
3/LPC 
4/vocoder+different channel
swops/arrangements 
x/klatt screwed/bent 
x/other filter 
x/raw wormed klatt
x/wormed vosim 
x/wormed x/y filter

+ variations say on vosim etc...
+ other speech synths

++ vocoder options with different sources - square wave, white noise etc.

all modes doubled by worm - worm from base through parameter
constraints for each. trigger resets to base. thus double for each mode more or less

* progress

** 4/11/2015

- stripped code and it compiles

** 9-10/11/2015

- knobs left/right from top (pcb and lach=test) = 0/mode-(2..3)
1/selX.egX-(3..2) 2/speed-(0..4) 3/end-(4..1)
4/trigthresh/vocoderfreq/othersel.eg/selY-(1..0) SEE audio.h

- input=threshold/vocoder_voice

- question of scheduling: examples? trigger_to_sync needs to be in
  reading in code (and trigger say new phoneme), braids operates with blocks-sync_buffer and render_buffer?

what is framesize for audio=32 x u16//

- and how frames work for speech/klatt? - frame is 256 samples = 512 bytes

frame=XmS of audio output p so we have ms at 32K = 

*** - list modes and examples: 

0/klatt 1/vosim 2/x-y filter 3/LPC 4/vocoder+different channel
swops/arrangements x/klatt screwed x/other filter x/raw wormed klatt
x/wormed vosim x/wormed x/y filter

+++ vocoder options with different sources - square wave, white noise etc.

all modes doubled by worm - worm through parameters for each

- what are other speech synth/modes??? LIST from earthvoice2:

raw//basic klatt parameters?

[1- NON - as is too much timing based!  robo: arduino = 8 bit TTS:same as robo above]

2- DONE sam - not TINYsss....: at https://github.com/s-macke/SAM/tree/master/src ?
sam: It is an adaption to C of the speech software SAM (Software Automatic Mouth) for the Commodore C64 - 8 bit and messy
tinySAM.c: small SAM above - 8 bit
SAMarduino: arduino of tinySAM above - 8 bit

3-
Talkie TI-99 DONE - LPCcode: :LPC - encode new words with QBoxPro/windows... TI99

[4-Tiny Speech Synth: C code - TinySynth.h 16 bit -> tiny.c]

[5-/afs/athena/astaff/project/phones/Speak emulates SPO256 - not really - premade samples]

[6-other: cantarino - /root/projects/ERD_modules/older/euro-modules/Talko/Software/Canto]

7- *braids(=rendervowel and rendervowelfof)* DONE

8-DONE:

Formlet as filter in SC: [[file:~/SuperCollider-Source/server/plugins/FilterUGens.cpp::void%20Formlet_next_1(Formlet*%20unit,%20int%20inNumSamples)][file:~/SuperCollider-Source/server/plugins/FilterUGens.cpp::void Formlet_next_1(Formlet* unit, int inNumSamples)]]

LPC: [[file:~/sc3-plugins/source/NCAnalysisUGens/LPCAnalysis.cpp::*%20LPCAnalysis.cpp][file:~/sc3-plugins/source/NCAnalysisUGens/LPCAnalysis.cpp::* LPCAnalysis.cpp]] and LPCsynth

- 2. 16 channel bandpass/formant/vocoder: ladspa DONE?in effect.c= vocoder.c

or vst-mda version: mdaVocoder.cpp TEST/TRY mdavoc=input and mdavocoder? see effect.c/mda...DONE

///????DONE???

X/Y//simple formant filtering (above)//generic filter conv. bbandpass, biquad, bandpass in effect.c and setup of 

and biquad in doformantfilter

- formant frequency/vowel table (vowels announced from buf16 as
  text->vowels,Q,length of vowel?)
  ????===arm_biquad_cascade_df1_init_f32??? in main.c in DI

///

formant ugens: http://gurzil.livejournal.com/15375.html

SC synthdef for vowels with BBandPass : http://sccode.org/1-4Vk

** xxx

*This week to have basic scheduling for klatt and knob allocations, memory. Also kind of template for other generators*

*template should be triggerable version and free-running version - mark each as such!*

** 11/11

- can we have say 128k contig memory? can use say 120k but need to assign memory to ccm if need more than 8k for other tasks

but not enuff memory in that case and can't program it (look for
larger arrays?) - set now to 32768 so can do loggy as is and can
always change loggy

will need to look into stm32_flash.ld for ccm definition - TESTed okayyyy....

eg. u16 sin_data[256] __attribute__ ((section (".ccmdata")));  // sine LUT Array

FIXED 12/11

- stmlib => fft etc. ???

so we put eg.  int16_t pWavBuffer[3840] __attribute__ ((section (".ccmdata")));

// testing now basics - why is so quiet?

// parwave is in nsynth - this handles the klatt frames

*** final 11/11 notes

- need to break down phoneme frames and/or move phoneme generation out
  of audio.c interrupt as is too long/slow - also as if we re-trigger
  fast then is only start of phoneme we hear...

  moved out of interrupt which means we have 32 samples/trigger always issue (so is 32 samples max slowed)- seems okay now

- to test all phonemes... also still question of volume to solve - HW on test board?

[- enter_phonemes() in phtoelm is executed only once? and can we bypass
  this for individual phonemes? or is case of phoneme and last one?]

/// all of rsynth is about transitions between phonemes and we just
have one - so simplify or fake this/make longer phoneme cases. see holmes.c

/BUT/and our list of phonemes is the lookup list - to figure out what we
need to send to holmes for 2nd part and simplify holmes for 1 phoneme 12/11
or do X/Y of 2 phonemes - but what of trigger? or trigger on max!

either way simplify to numericals an no string stuff/memory 

- klatt/rsynth on pc verbose to check all...-> see Downloads/rsynth-2.0 (also updated rsynth version?)

- TODO: raw klatt with certain start positions and worm off from these within parameter bounds for each

- TODO: generate and test square for vocoder

** 12/11

- fixed stm32_flash.ld CCM mistake

- retest trigger - fixed as VOLATILE

- break down rsynth - problem is if we even have 1 phoneme + stress then is ended!

so we need to open up holmes.c so keeps running and writes directly
into audio_buffer and deals with trigger/phoneme selection (is always
one phoneme behind? - but not great idea as we can't look ahead?

how do we get stress and dur from phoneme?

this is dur in phone_to_elm

if (!(p->feat & vwl))
stress = 0;
t += phone_append(elm,StressDur(p,stress));
(int) (StressDur(p, stress, islong)));
#define StressDur(e,s,l) ((e->ud + (e->du - e->ud) * s / 3)*speed)

for each one in elements.def

next bit is stress?

stress is either 0,1,2 or 3

so we have phoneme_num//dur//stress and 1/6/0 seems to be ending (twice??) *TODO* make that array which is test_elm

- also need to get rid of pwavebuffer and write straight IN DONE

- 32k=64k=128 frames

- can enlarge audio buffer now we have fixed ccm so could be 60k =
  120k = say 200 frames audio.h = 58870 with log_gen.py calculating
  end

*if we enlarge then re-do loggy for this size* DONE

*69 is number of phonetic elements - stress or no stress = 69x4=272 - close to 255???* leave stress as 0 for now

*** notes

- how does CV select phoneme - like how often do we sample CV to give
phoneme? do we have phoneme list which we run through into buffer and
shift out or? based on speed? as have it trigger is the one

- working on run_holmes which is constant running and trigger-able -
  test this and then figure out how to update list... 

- clip in nsynth *4.0f for volume increase ADDED - VOLUME fixed

- still scheduling question - say for run_holmes so doesn't just cycle
  over itself... wait until playhead passes how?

// and run_holmes seem start with phrase fine and run DOWN - if we run continuous then will tail off!

- run_holmes as 2nd mode (MODE=1)

- how does run_holmes know how much to fill buffer? - overfill?/average - silence is ok

*** TODO

- triggering and scheduling is main issue// add to end of phoneme list and shift left or just re-write (more modes?)re-write!-TODO

- mode1-run_holmes - use trigger to freeze any changes to phoneme list as extra mode-TODO

*TODO: proof tests on VOSIM(sc/braids/csound/sc-formlets),XY(bbandpass,doformantfilter, biquad), vocoder(ladspa?/mdavoc=input and
mdavocoder?/mdatalkbox/pv_vocoder=justFFTsofar), LPC(talkie and SC), canto etc.* nearly DONE

*TODO: changes suggested above//how to test-simulate triggerCV also*

** 13/11

Note that trigger will always be slow as we _just_ process the buffer in audio.c - not LIVE...

Working on *VOSIM_SC* versionings - trigin could also be seperate timer/counter - controlled by? - Impulse.ar - LFUGens.cpp

- need to organise parameters for VOSIM as so far we don't do decay

- writepos always given and returned so we can sync

- single VOSIM - until it ends, how is triggered? - but this is just SC triggering

*** notes

- do impulse.ar in vosim, but also like random triger variant that we have

VOSIM_SC:

*ar (trig: 0.1, freq: 400, nCycles: 1, decay: 0.9, mul: 1, add: 0)
Arguments:
trig [ar kr] starts a vosim pulse when a transition from non-positive to positive occurs and no other vosim is still going. audio rate input will produce sample accurate triggering.
freq [ar kr] the frequency of the squared sinewave.
nCycles	- the number of squared sinewaves to use in one vosim pulse. nCycles gets checked when VOSIM receives a trigger.
decay - the decay factor.

eg. http://doc.sccode.org/Classes/VOSIM.html

*do away with END and use as 3rd parameter - eg. in phonemes do we even use 2nd par?*DONE

*TODO: rationalise phonemes so there are 64 or is probability table - also order in which they are arranged could follow probability of transitions...*DONE

** 15/11

Different voices:

Note in Klatt: The facility to use a sampled natural excitation
waveform has been implemented. Naturalness of the resulting synthetic
speech can be greatly improved by using the glottal excitation
waveform from a natural speaker, especially if it is the speaker on
whose voice the synthesis is actually based. This may be obtained
indirectly by inverse-filtering a vowel.

HOW? - this function is in different klatt: [[file:~/Downloads/www.laps.ufpa.br/aldebaro/classes/04procvoz1sem/Klatts/Klatt-C-Windows-F0flutter/Src/parwave.cpp::/*]]

but we could use incoming samples as this? inverse filtering?

Take a recorded vowel and locate the overall peaks and valleys in the spectrum (the formants) by using an LPC (linear predictive coding) algorithm

These peaks and valleys, at least theoretically, should represent the resonances in the mouth caused by a given tongue shape

Use this information to reconstruct the voicing signal (the source) without those peaks and valleys

This is accomplished by inverse-filtering the signal with the LPC, raising the parts of the spectrum which the LPC says are low, and lowering the parts which the LPC says are high. The end result, ideally, will be the source signal as if the person had no vocal tract at all.

http://doc.sccode.org/Classes/LPCAnalyzer.html

but inverse filter?

https://github.com/freedv/codec2/blob/master/src/lpc.c

[[file:~/projects/ERD_modules/worm/lpc.c::FILE........:%20lpc.c][file:~/projects/ERD_modules/worm/lpc.c::FILE........: lpc.c]]

Klatt:Flutter is one of few globals?

also NATURAL and IMPULSIVE in def_pars.c to test as is always now set to impulsive

now klatt_params - see also http://linguistics.berkeley.edu/plab/guestwiki/index.php?title=Klatt_Synthesizer_Parameters

*** TODO

- x/y bandpass - which ones in DI? ABOVE

- vocoder/s - see ABOVE

- alt speech synths listed ABOVE

- klatt LPC stuff

- finish making/remaking phoneme list in klatt/run_holmes above and re-check if runs off/how to re-start or does that happen now?

/////

- raw klatt and other wormings....

- phoneme probabilities (n-grams) and all TODO above!

** 16/11

- added resync on mode change - to TEST all

- phoneme list rewrite based on probabilities so now 64 phonemes

- started on robo/tts - compiles so far but need to know how phonemes are represented - by way of list and stops/numerals etc... TODO!

phonemesToData(textp,s_phonemes)

*** TODO:

- howmany written should depend on readspeed [note: that we can also
  break down klatt frame into smaller chunks as long as we buffer and
  keep track of these in an array]

- Klatt elements - new definitions, other voices eg. whisper, croak, female?

also X= change parameter, Y select parameter - need list and constraints see klatt_params - also this will use code in holmes.c

notes: klattsyn.py, new python code in downloads


*** phoneme probabilities 

phoneme_prob.py

using rsynth-2.0 printing phonemes from
/root/projects/earthcode/worm/beddoesvol1gosse_trimmed we can lose a
few phonemes and re-order as:

u8 phoneme_prob_remap[64]={1, 46, 30, 5, 7, 6, 21, 15, 14, 16, 25, 40, 43, 53, 47, 29, 52, 48, 20, 34, 33, 59, 32, 31, 28, 62, 44, 9, 8, 10, 54, 11, 13, 12, 3, 2, 4, 50, 23, 49, 56, 58, 57, 63, 24, 22, 17, 19, 18, 61, 39, 26, 45, 37, 36, 51, 38, 60, 65, 64, 35, 68, 61, 62}

[prob_other to be used for other phoneme description on laptop - in modified rsynth2.0]

** 17/11

DONE:

- end removed and replace as SELZ
- mdavocoder working but could do with some tuning - try other vocoders too!
- ladpsa vocoder running
- basic bandpass running with X/Y code - seems work fine. maybe extend with extra formantsTODO...

- pick vowel formants using doformant - TODO: cross-fade to smooth out, use own carriers

also more formants at: https://github.com/supercollider-quarks/Vowel/blob/master/Vowel.sc

need to remember how to convert db and bw!

- formlet code = FOF - see also: http://composerprogrammer.com/teaching/supercollider/sctutorial/12.2%20Singing%20Voice%20Synthesis.html

need to be able to change frequency

SAM working but only with arrays in RAM - not CCMdata or FLASH -????

do we need to init like:

const unsigned char flags[81]  __attribute__ ((section (".flash")))={
with [81]???? TRY!

*** Notes:

BPFSC and BBandpass would operate as fixed and this is what we have already so leave for now
with doformant - somehow need to figure out offset and mix for this for kind of singing - multiple voices/oscillators

Also seems like common to some effects that we would have oscillator/noise etc. triggered?

for SAM: http://www.retrobits.net/atari/sam.shtml

*** TODO: - PRIORITISE: changes/TODO as above and all tests

- possibilities of vocoding with buffer generated audio

*- Borsboom/zerius vocoder in earthvoice2 dir to look at*

- mdavoc.c is wierd for carrier source

- look at propellor/cordic thing for worm tract simulation

- klatt as singing - constant sounds?

- different voices in sam.c - parameter live altering, speed of sam, lookup array for phonemes

- trigger/schedule for one word/phrase after the other

- pull audio-bufsz back up from 32768

** 18-19/11

- done lpc.c (talkie) - but triggering - always issue with free-running round in buffer overwrites itself

- using encoder - calc.m and romgen from talkie with freemat and online convertor - use 8 KHz 16 bit mono recordings to encode words for lpc.c

- Formant object also in SC - done

** TODO

- wormlpc (but there in analysis phase also see sc live stuff),
  wormvoice simulation, how to do crossfading - need run 2 filters

- increase LPC vocabulary - pointers to flash works or not?

- *triggering and scheduling on all*

- braids code only for worming

- Borsboom vocoder to port to static memory allocation [vocoder added and compiles/runs but not result and slows incoming audio]

- LPC live analysis = [[file:~/sc3-plugins/source/NCAnalysisUGens/LPCAnalyzer.cpp::/*]]

*Think about* - mixing of round-buffer and live(where is no speed),
scheduling questions always... eg. vosim is more in live audio.c than
round buffer and others other way round...


** 20/11

- vocoder fixed - WHICH ONE?-borsboom in vocoder dir? (was sqr in fft_mag) - without overlap and would be nice to try different carriers
(check also timing in interrupt? - done and seems okay so far)

- started on [[file:lpcanalysissc.c::*%20LPCAnalysis.h][file:lpcanalysissc.c::* LPCAnalysis.h]] - just rough filling in so far

- braids for worming: [[file:braidworm.c::/%20vosim/vowel/vowelfof][file:braidworm.c::/ vosim/vowel/vowelfof]] - again filling in - also we need dsp from stmlib!

Vowel.sc definitions at: [[file:~/projects/earthvoice2/Vowel/Formants.sc::/%20Pseudo%20Ugens%20to%20be%20used%20together%20with%20Vowel][file:~/projects/earthvoice2/Vowel/Formants.sc::/ Pseudo Ugens to be used together with Vowel]]

and Vowel.SC there!

along with Formants and BPFstack (multiples of Formant we have and BPF) which could be adapted also for these vowel lists.

how vowels compare with braids?

interleaving between vowels

SC dynklank resonators - example in Vowel.schelp - klank= [[file:~/SuperCollider-Source/server/plugins/OscUGens.cpp::void%20Klank_Dtor(Klank%20*unit)][file:~/SuperCollider-Source/server/plugins/OscUGens.cpp::void Klank_Dtor(Klank *unit)]]

** 22/11

NOTES: phoneme_prob_other is used for our phoneme probabilities on
laptop/NOT worm with say.c modified in rsynth-2.0 as marked with xxxxx

- modded just to print selected phonemes (what was scheme which was just their number as in Elements.def?), and re-modded just to say these phonemes

- but conversion of text to phoneme using say.c repeats sections? -
  FIXED but should do 2 versions of say and co, also vague fullstop
  business 

TO FIX: // fullstops // 2 versions // readable phonemes

TODO: 

- summary for each mode so far and each TODO

- how klatt frame size relates to each change in parameters - where we need to intersect for raw klatt? nsynth -> parwave?

"Each frame of parameters usually represents 10ms of output speech. Two
(simple!) example parameter files are supplied with the package."

at 32000 samples per sec 10ms=320 samples - in def_pars.c we have 8ms per frame = 256 samples

see also: http://www.asel.udel.edu/speech/tutorials/production/gensyn.htm

[- pull rsynth-2.0 into src git]

- port rsynth changes back to darkint voice code

** 23/11

TODO from yesterday TODO

+

finish working through braids, lpcanalysis, vowel.sc, stk above and look at dynklank resonators:

note:

inline float32 zapgremlins(float32 x)
{
	float32 absx = std::abs(x);
	// very small numbers fail the first test, eliminating denormalized numbers
	//    (zero also fails the first test, but that is OK since it returns zero.)
	// very large numbers fail the second test, eliminating infinities
	// Not-a-Numbers fail both tests and are eliminated.
	return (absx > (float32)1e-15 && absx < (float32)1e15) ? x : (float32)0.;
}

+ mul in SC portings? and db and bw in vowel parameters - how we did this for doformant

+ const arrays of vocal filter parameters eg. for klank resonators

+ basic LPC to try out

// so break down to:

1- new experiments/code as above
2- summary and tweaking of what modes we have so far: basic excitation osc generation, fixed filters stored
3- scheduling and triggering schemes overall...
4- towards manual
5- HW tests for basic design and trigger in! IN PROGRESS
6- worming and raw Klatt/LPC broken down

** 24/11

hardware - powers up fine. need to rewire top 3 potis to mirror CV ins
below (do with cuts marked on diagram), enlarged poti side holes - redone in revised.brd//TODO
after all tests: recheck all, zones, vias.

** 25/11

Board tested and audio working. TODO: test potis and CV... 

*** Hardware notes:

- Define as TEST in Makefile - audio.c for DARKINT test board -  also as worm.brd output is on LEFT
not on RIGHT!

- Programmer header is straight to STLINK rather than swop we have in DARKINT

*** Software

- braids - compiled and working - just need to tweak parameter ranges... and WORM out as is too clean (esp... RenderVowel)
also if we can use square etc. as excitation?

-lpcanalysis - compiles and seems to work from SC - need more exciters...


TODO: 

4-dynklank resonators - save coeffs as table first

/// more structural

2-vowel.sc - lists for other generators to use...

5-basic LPC code to re-worm

6- klatt to re-worm

+ carrier generation and use of audio_buffer as either carrier or as voice?

** 27/11

Cook - singer/SPASM - only code is in CLM but see TRM below 

see also STK/voicform: tick in includes eg. [[file:~/darkint/docs/stk/include/VoicForm.h]]

** 30/11

Vocal tract simulations: TRM in gnuspeech: http://svn.savannah.gnu.org/viewvc/nextstep/trunk/src/softwareTRM/?root=gnuspeech

and: https://github.com/lmjohns3/py-trm/blob/master/README.rst

see [[file:~/projects/ERD_modules/worm/docs/softwareTRM/tube.c]]

//List excitations: square wave, cluster of sine waves, looped excitation, white noise, impulses - what else and how? as tables?

//VoicForm: compiles// to testTESTED

Phoneme definitions at: [[file:~/sc3-plugins/source/StkUGens/stk-4.4.2/src/Phonemes.cpp]]

SingWave modulates input wavetable (raw file=impuls20.raw) could be
buffer or we use as table - what is format of impuls20.raw? 16 bit
signed but BIG ENDIAN!

FormSwep is filter sweepable.

[see also:   onezero_.setZero( -0.9 ): [[file:~/sc3-plugins/source/StkUGens/stk-4.4.2/src/OneZero.cpp]]
  onepole: [[file:~/sc3-plugins/source/StkUGens/stk-4.4.2/src/OnePole.cpp]] ; noiseEnv_.setRate( 0.001 ) [[file:~/sc3-plugins/source/StkUGens/stk-4.4.2/src/Envelope.cpp]]
]

//////////////////////

// phoneme definitions from braids, from SC, from STK ???

TODO: TRM!!!

** 2/12

- VoicForm kind of works but we need to test further and add vibrato
  and controls. also if we go further with STK (and eg. FMVoices with
  same dependencies on numerous other files)??? NON!

- preparing DONE

*** *tube.c*

- floats, no tempfiles, compiles now... TODO: memory management, output-framesize? DONE

Notes:

dataEmpty: Converts available portion of the input signal to the new sampling
rate, and outputs the samples to the sound struct.

buffer is 1024,,,, functions: flushbuffer, datafill , *dataempty writes to temp file*...

*** TODO still:

- play with TRM/tube on PC - worm simulation - width of mouth/nose???? DONE
- implement generic wavetables, envelopes etc. for excitations and how might work with buffer
- TRM portings DONE
- triggering, list of modes and tweaks/modifiers to each one - finalise almost
*- wormings, raw LSM tests, raw KLATT*

- tie up formant filters maybe see https://github.com/4ms/SMR https://www.keil.com/pack/doc/CMSIS/DSP/html/group___g_e_q5_band.html

** 3/12

TRM Notes:

- At 32k samples we have 96k samples for 12 sets of parameters in input (so 96/12=8k per set)

- Basic parameters and then frame parameters

- What is set with calloc and can it be set as array/not dynamic?

wavetable can be static allocated (is only rewritten if source is pulse)

number of taps is calculated in init of filter

    FIRData = (float *)calloc(numberTaps, sizeof(float)); // TODO as fixed?
    FIRCoef = (float *)calloc(numberTaps, sizeof(float));

  return ((INPUT *)malloc(sizeof(INPUT))); // TODO? - from addinput? 

this is inputtable which is each parameter frame/set +1???? so if we have fixed number of parameter sets??? we can fix this...

fixed as max size for both FIR??? could overflow

** 4/12

- TRM tube.c init_parameters but still need get rid of dynamic
  memory - we just have one input-table (+1=2) so thats 8k samples
  into audio_buffer (leave dynamic as filter needs)// tableone and tabletwo

- how do we know when phrase/frame is done? to avoid overwriting? is just one call to synthesize?

- crashes so far in: dataEmpty!FIXED - double initialisation as we
  initialize in main: initializeSynthesizer();// includes call to
  init_parameters !!!! TUBE.C - TRM! and was 0.0 for volume in first of frames from input

- could simplify the linked list as we just have 2 frames (1+interpolation) TODO!

*** TODO: 

- that we could have several different base vocal tract modes for TRM
  -> parameter_list or use SELY/SELZ to vary the main parameters as
  below.

- trim working modes // run thru - also twin buffers - switch vocoder voice/excitation etc...

** 5/12

- list of TRM parameters

TRM parameters see: http://pages.cpsc.ucalgary.ca/~hill/papers/synthesizer/body.html

we have for each frame:

	glotPitch = strtod(ptr, &ptr);
	glotVol = strtod(ptr, &ptr);
	aspVol = strtod(ptr, &ptr);
	fricVol = strtod(ptr, &ptr);
	fricPos = strtod(ptr, &ptr);
	fricCF = strtod(ptr, &ptr);
	fricBW = strtod(ptr, &ptr);
	for (i = 0; i < TOTAL_REGIONS; i++) // 8 values
	    radius[i] = strtod(ptr, &ptr);
	velum = strtod(ptr, &ptr); // last value

in [[file:~/Downloads/gnuspeech-0.9/Applications/Monet/samples/diphones.degas]] we have:

///
*a phone vocoid voiced 

	microInt: *0.000000		r2: *0.650000
	glotVol: *60.000000		r3: *0.650000
	aspVol: *0.000000		r4: *0.650000
	fricVol: *0.000000		r5: *1.310000
	fricPos: *5.500000		r6: *1.230000
	fricCF: *2500.000000		r7: *1.310000
	fricBW: *500.000000		r8: *1.670000
	r1: *0.800000		velum: *0.100000
///

So microint and pitch?

[[file:~/Downloads/gnuspeech-0.9/Applications/TRAcT/tube.c]] is same as our tube model...

maybe keep glotPitch as static or change with SELY

but we leave microint as first in float input_frames[64][16]=

TO TEST with what could be SILENT phonemes?????

///
Also NOTE:

Parameters
microInt
Min: -10.000000  Max: 10.000000  Default: 0.000000

glotVol
Min: 0.000000  Max: 60.000000  Default: 60.000000

aspVol
Min: 0.000000  Max: 60.000000  Default: 0.000000

fricVol
Min: 0.000000  Max: 10.000000  Default: 0.000000

fricPos
Min: 0.000000  Max: 7.000000  Default: 5.500000

fricCF
Min: 100.000000  Max: 20000.000000  Default: 2500.000000

fricBW
Min: 250.000000  Max: 20000.000000  Default: 500.000000

r1
Min: 0.000000  Max: 3.000000  Default: 0.800000

r2
Min: 0.000000  Max: 3.000000  Default: 1.500000

r3
Min: 0.000000  Max: 3.000000  Default: 1.500000

r4
Min: 0.000000  Max: 3.000000  Default: 1.500000

r5
Min: 0.000000  Max: 3.000000  Default: 1.500000

r6
Min: 0.000000  Max: 3.000000  Default: 1.500000

r7
Min: 0.000000  Max: 3.000000  Default: 1.500000

r8
Min: 0.000000  Max: 3.000000  Default: 1.500000

velum
Min: 0.000000  Max: 1.500000  Default: 0.100000

/////

Also useful:

Male
length	17.5
tp	0.40
tnMin	0.24
tnMax	0.24
glotPitch -12.0

Female
length	15.0
tp	0.40
tnMin	0.32
tnMax	0.32
glotPitch 0.0

LgChild
length	12.5
tp	0.40
tnMin	0.24
tnMax	0.24
glotPitch 2.5

SmChild
length	10
tp	0.40
tnMin	0.24
tnMax	0.24
glotPitch 5.0

Baby
length	7.5
tp	0.40
tnMin	0.24
tnMax	0.24
glotPitch 7.5

TODO:

- also test with say 4 frames and how do away with linked list business - setinput and setcontrolrate... - should work///

- how/do we alter main params - also say map SELX->phoneme, SELY-> length, SELZ-> glotpitch (so re-init if changes or?)

** 7/12

- checked revised panel

- checking revised brd and fixed missing CV4. checked - matching, works...DONE
- double-check again and add zones and vias and re-check gerbers

*** TODO:

- finish TRM changes=linked list, longer list of frames, change vocal tract as above and WHEN? - length, glotpitch
- all working models/tweaks
- excitations and buffer fills/switches
- trigger code
- wormings and tables of min/max parameters for each mode - CONSTRAINTS
- raw KLATT and LSM wormings
- check CV allocations for new board and test!

- trigger//when_mode_change in main -??? 
- look at SMR??? https://github.com/4ms/SMR

** 14/12

- re-acquaint with tube.c - where we can deal with say glotpitch and
  where inits are made --> most of initializeSynthesizer uses
  nyquist/samplerate which is determined by tube length?

solutions as length and pitch is what we want to vary = pitch should
be fine live, and have set of tables for different tube lengths as above

but still need to clean up linked list, how to add new frames and so
on, also how that change in glotPitch works with interpolation?

** 15/12

- added lpc dir from SLP - TODO: run commandline tests from docs/SLP, fix mallocs, work in

- votrax?
  https://github.com/OpenEmu/UME-Core/blob/master/mame/src/emu/sound/votrax.c
   - see UMECORE under sound in docs - also some other speech chip emulations eg.  TSI S14001A, [TMS 5110/5220A (speek and spell)-LPC=TALKIE!!]

[[file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/votrax.c::Simple%20VOTRAX%20SC-01%20simulator%20based%20on%20sample%20fragments.][file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/votrax.c::Simple VOTRAX SC-01 simulator based on sample fragments.]]

- TODO: port VOTRAX DONE but not working

** 18/12

- tested CV hardware all fine // switched round in audio.h (on x60 so
  transfer here), need tweaks for resonance (could be selz?) on X/Y
  filter, also ifdef switch for INPUT also in audio.c and maybe try other bandpass?

- or SELZ for x/y filter can scale both formants for size of throat/voice

- effect.c x/Y filter should be in parallel, amplification and varying Q for each? use of example vowels???

how again to convert bandwidth to Q: 

~bpOctavesToRq = { arg octaves; (pow(2, octaves) - 1) / pow(2, octaves).sqrt }; // appears wrong way round!!

say 130 hz for x, 70 hz for y?

find formant table from SC again: Vowel.sc definitions: [[file:~/projects/earthvoice2/Vowel/Vowel.sc]]

eg. 			.put( 'a', 'soprano', 'freq',[ 800, 1150, 2900, 3900, 4950 ])
			.put( 'a', 'soprano', 'db', [ 0, -6, -32, -20, -50 ])
			.put( 'a', 'soprano', 'bw',	 [ 80, 90, 120, 130, 140 ])

but what is bw, how relates to Q, and dbamp... but these seem to work with BBandPass as evidenced by below...

- how we do db amp? but more how this becomes x and y scalings with bandwidth????

bw also goes up as freq goes up...

also from FormantTable.sc for BBandPass:

		table.put(\sopranoA, [[800, 1150, 2900, 3900, 4950], [0, -6, -32, -20, -50].dbamp, [80, 90, 120, 130, 140]]);
		table.put(\sopranoE, [[350, 2000, 2800, 3600, 4950], [0, -20, -15, -40, -56].dbamp, [60, 100, 120, 150, 200]]);
		table.put(\sopranoI, [[270, 2140, 2950, 3900, 4950], [0, -12, -26, -26, -44].dbamp, [60, 90, 100, 120, 120]]);
		table.put(\sopranoO, [[450, 800, 2830, 3800, 4950], [0, -11, -22, -22, -50].dbamp, [70, 80 ,100, 130, 135]]);
		table.put(\sopranoU, [[325, 700, 2700, 3800, 4950], [0, -16, -35, -40, -60].dbamp, [50, 60, 170, 180, 200]]);
		table.put(\altoA, [[800, 1150, 2800, 3500, 4950], [0, -4, -20, -36, -60].dbamp, [80, 90, 120, 130, 140]]);
		table.put(\altoE, [[400, 1600, 2700, 3300, 4950], [0, -24, -30, -35, -60].dbamp, [60, 80, 120, 150, 200]]);
		table.put(\altoI, [[350, 1700, 2700, 3700, 4950], [0, -20, -30, -36, -60].dbamp, [50, 100, 120, 150, 200]]);
		table.put(\altoO, [[450, 800, 2830, 3500, 4950], [0, -9, -16, -28, -55].dbamp, [70, 80, 100, 130, 135]]);
		table.put(\altoU, [[325, 700, 2530, 3500, 4950], [0, -12, -30, -40, -64].dbamp, [50, 60, 170, 180, 200]]);
		table.put(\counterTenorA, [[660, 1120, 2750, 3000, 3350], [0, -6, -23, -24, -38].dbamp, [80, 90, 120, 130, 140]]);
		table.put(\counterTenorE, [[440, 1800, 2700, 3000, 3300], [0, -14, -18, -20, -20].dbamp, [70, 80, 100, 120, 120]]);
		table.put(\counterTenorI, [[270, 1850, 2900, 3350, 3590], [0, -24, -24, -36, -36].dbamp, [40, 90, 100, 120, 120]]);
		table.put(\counterTenorO, [[430, 820, 2700, 3000, 3300], [0, -10, -26, -22, -34].dbamp, [40, 80, 100, 120, 120]]);
		table.put(\counterTenorU, [[370, 630, 2750, 3000, 3400], [0, -20, -23, -30, -34].dbamp, [40, 60, 100, 120, 120]]);
		table.put(\tenorA, [[650, 1080, 2650, 2900, 3250], [0, -6, -7, -8, -22].dbamp, [80, 90, 120, 130, 140]]);
		table.put(\tenorE, [[400, 1700, 2600, 3200, 3580], [0, -14, -12, -14, -20].dbamp, [70, 80, 100, 120, 120]]);
		table.put(\tenorI, [[290, 1870, 2800, 3250, 3540], [0, -15, -18, -20, -30].dbamp, [40, 90, 100, 120, 120]]);
		table.put(\tenorO, [[400, 800, 2600, 2800, 3000], [0, -10, -12, -12, -26].dbamp, [40, 80, 100, 120, 120]]);
		table.put(\tenorU, [[350, 600, 2700, 2900, 3300], [0, -20, -17, -14, -26].dbamp, [40, 60, 100, 120, 120]]);
		table.put(\bassA, [[600, 1040, 2250, 2450, 2750], [0, -7, -9, -9, -20].dbamp, [60, 70, 110, 120, 130]]);
		table.put(\bassE, [[400, 1620, 2400, 2800, 3100], [0, -12, -9, -12, -18].dbamp, [40, 80, 100, 120, 120]]);
		table.put(\bassI, [[250, 1750, 2600, 3050, 3340], [0, -30, -16, -22, -28].dbamp, [60, 90, 100, 120, 120]]);
		table.put(\bassO, [[400, 750, 2400, 2600, 2900], [0, -11, -21, -20, -40].dbamp, [40, 80, 100, 120, 120]]);
		table.put(\bassU, [[350, 600, 2400, 2675, 2950], [0, -20, -32, -28, -36].dbamp, [40, 80, 100, 120, 120]]);

////

- votrax.c sc01.bin is 512 bytes (0x200) - 64 phonemes = 8 bytes each

** 19/12

- vowel tables
- MAME portings - test
- excitations
- wormings/tweaks all modes
- *we always need transition from previous phoneme for each mode (inc X/Y)!*

** 22/12

- Mode 11-     Formant_process crashes????

** 23/12

- porting votrax.c from mame as above - compiles (no tested on ARM) but no output?
//TODO: compiles but no output, all doubles, ceil/sqrt/tan/fabs to tanf etc... float

- what is missing? does that code even work?

NOTES:

	MCFG_VOTRAX_SC01_ADD("votrax", 1700000, votrtnt_votrax_interface ) /* 1.70 MHz? needs verify */

[[file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/mess/drivers/votrtnt.c::*%20Votrax%20Type%20'N%20Talk%20Driver][file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/mess/drivers/votrtnt.c::* Votrax Type 'N Talk Driver]]

how/where we write data to SC01/votrax: WRITE8_MEMBER( votrax_sc01_device::write )

- now test code seems to work // 0x3f = 63 // need to figure out speeds!

** 28/12

- list of each mode and what needs to be done TODO!

- votrax.c some sounds but timing is out - how do we know when new phoneme comes:

sound_stream_update somehow with samples from m_stream->update();

is how mame emulates timing but must be some shortcut:

[[file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound.c::void%20sound_stream::update()][file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound.c::void sound_stream::update()]]

and then number of samples is: (update_sampindex - m_output_sampindex)

	// how long is phoneme in samples????????

also:

[[file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/sp0256.c::GI%20SP0256%20Narrator%20Speech%20Processor][file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/sp0256.c::GI SP0256 Narrator Speech Processor]]


** 31/12

- not much further with votrax.c - sounds produced but timing/length
  of phonemes from ROM doesn't come close to match data
  sheet/unintelligble speech

and: https://batchloaf.wordpress.com/2012/09/21/ugly-speech-synthesis-in-c/

- how to use what we have from votrax - break out parameters

speech chips- ti99=talkie DONE?/ SP0256 by Joseph Zbiciak-above in MAME but not free/ VOTRAX SC01-????

csound- vowgen:   // only find [[file:~/projects/ERD_modules/worm/docs/Csound6.05/Opcodes/fm4op.c]] which is like voices/voicform noted above NOT REALLY

and LPC: [[file:~/projects/ERD_modules/worm/docs/Csound6.05/util/lpanal.c::lpanal.c:]]

///

** 4/1

*** rethinking hardware design

- check if noise is there on in/out which causes X/Y filter strangeness

- maybe different solution for CV inputs?

- hardware encoder for main mode?

*** software and plan

- 48k as new sample rate? or? stick on 32k!

- finish portings=nvaccess????///31/12 list above// run thru all in docs and discard

- break down to excitation (buffer) // tract/processing/speech (buffer) // incoming (buffer)

- test code different excitations - list here: white noise/gaussian etc, pulses, vosim/decaying sines, square/triangle // what else?

- collate all vowel/phoneme parameters and control parameters in one
  place (and any conversions between these eg. Q and bandwidth, amp
  and db): put in collated_forms.h - but we need to figure out
  conversions, how we made these in the past, and also what works for bandpass:

bandpass options: bandpassx/y(owl), bandpasses in SC=BBandPass/BPFSC, doformantfilter=arm_biquad (init only), 

- do we need voiced/unvoiced and pitch detection... also incoming LPC

- coherent modular solution for _all_ generation - howmuchneeded,
  trigger generation and testing, all processing in audio.c, main for
  changes

- own worm speech synth algo...

- vocoder needs much work... what do we have so far? see also: http://gurzil.livejournal.com/15375.html and pvsvoc in csound code.

** TODO

- X/Y with different bandpass tests

- retest arm_biquad _without_ mult in co-efficients...

- debug messages in klatt for holmes/interpolation/stresses to figure
  out how to manipulate single phonemes - but these are never single...

- klatt question is always what is NEXT phoneme - if there isn't one (loop a list of phonemes) list->end then repeat

** 5/1

- modes at top of this doc, and structured working through of klatt/rsynth also above - porting of nvp.c to test

- have a look at: [[file:~/projects/ERD_modules/worm/docs/mage/src/mage.cpp::/*%20This%20file%20is%20part%20of%20MAGE%20/%20pHTS(%20the%20performative%20HMM-based%20speech%20synthesis%20system%20)%20*/][file:~/projects/ERD_modules/worm/docs/mage/src/mage.cpp::/* This file is part of MAGE / pHTS( the performative HMM-based speech synthesis system ) */]]

which also has vocoder code...

** 6/1 - 7/1 ++

TODO: 

1/port simple klatt and add constraints (test first on laptop->see genparam.cDONE): simpleklatt.c DONE- to test

2/round phonemes for klatt in mainbuffer simply - x/y position/change - speed of revolution and end-length calc/hit end of

3/finish port and test nvp.c: ipa.py calculates: phoneme times/duration->frameDuration,fadeDuration, pitch

see also: test_midiSing.py and hannah:

def queueFrame(self,frame,minFrameDuration,fadeDuration,userIndex=-1,purgeQueue=False):

player.queueFrame(frame,//frame=120,fade=100)

// how that translates to samplecount at samplerate=? test this and fade is fade across frame parameters?

// other globals eg. 	_curPitch=118
	_curVoice='Adam'
	_curInflection=0.5
	_curVolume=1.0
	_curRate=1.0

TODO: test generating a single frame (laptop?) DONE

4/rest of mame porting

*// but we need clearer idea of buffers  and scheduling... for now just test very basics...*

should be blackbox/generator for each mode which fills buffer in
audio.c (inside workings hidden inc. for klatt/mode 0 roundabout) -
each as function pointer and if needs run in main as scheduler

so we have function pointers eg.

generate_simpleklatt(generator, size, incoming, outgoing)

first klatt runs round and round in audio_buffer (but only at full
length of all phonemes) and we schedule updates (when/how - at speed of playback)

5/worm.c filled out with ideas

6/look into mage above// questions

** 13/1

- nvp.c working on laptop with phonemes defined - possible here to
  vary across short 32/100 sample frames: interpolation and length of
  phoneme, pitch of phoneme, vibrato, gain and other globals TODO-
  backport to ARM - inits etc. DONE

- also above variations for own worm voice synthesis in worm.c

** 14/1 - 15/1

*also to simplify - where is u16 and so on defined (from something in audio.h), clearer coding style for all underscores etc???*

- ported back nvp.c but still needs fix for buffer, and any
  interpolations between frame parameters

- we need a naming scheme to fix on: eg. for nvp algo:

init_nvp(void)

settings_changed_nvp(selx,sely,selz,struct of generic settings) - but
what are these settings for each? again wrap this/this is wrapper...

runframe_nvp(size)

generate_nvp(incoming,outgoing) is wrapper

+ generic struct for keeping track of wrapper

- also generic scheme for worming through parameter lists: worm simulation, length of param list

wormsim: see http://gamedev.stackexchange.com/questions/12059/why-do-objects-interpenetrate-in-this-simple-collision-solver

mass, velocity, size and direction ???

and: http://www.openprocessing.org/sketch/10781

RAVENs??? vocal tract length of 13 cm in ravens: formants: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3482666/

- nvp.c what is the full list of global and frame variables?

*TODO:*

- finish basic tests on ARM and ports above from TODO: nvp,
  klatt_simple, mame stuff=SP0256 by Joseph Zbiciak-above in MAME but
  not free, look at mage,
  voicform=file:~/projects/ERD_modules/worm/docs/Csound6.05/Opcodes/fm4op.c
  (check differences)

- what works well which we have so far?

- re-organise namings with wrappers for generate, all_changes_to_params and so on, check globals, all a bit more organised

- worming scheme/simulation, own worm tube/hybrid models

- record ravens - how to process? LPC?

- excitation questions, LPC research, TRM, klatt all done

- vocoder to finalise

- wrap up, tweak and test

** 18/1 

- see also vtsynth and vtcalcs/src (how matlab code relates - mex?) for vocal tract modelling - *perhaps leave these for next stage!*

vtsynth relates to vtcalcs(matlab?): 

VTCalcs is a vocal tract model written by Dr. Shinji Maeda. It was
originally available for DOS only. This Matlab version can be compiled
and run on any platform supported by Mathworks. In addition, a newer
version of the synthesizer is available (VTsynth). This synthesizer is
used in VTCalcs, but has to be compiled separately from the mex files
in VTcalcs.

** 19/1

- what needs testing/changing - nvp, klatt round robin and scheduling, simpleklatt:

nvp: phoneme length from ipa.py 0 from 6 to 60, 50 to 100 in
midi_sing... as param // so list all params:

also multipliers and frame param over-rides for different voicesDONE

klatt round robin: array of phoneme lengths!

- wrapping eg. generate - see TODO at top here (also naming schemes)

** 20/1

- for all question of large number of parameters to change: worm
  through, vectors of transformation, presets such as voices/phonemes
  to select and transition between if necessary

- for crow or raven voice use LPC and also try inverse filter/lpc
  thing for KLATT as source (??) - do this when we do all LPC tests

- praat installed for analysis

NVP:

- nvp_pc.c for pc version testings - interpolation, voice over-ride
  and mulsDONE, all params and length varying

// basic voice and null voice in place but we need a phrase for it to say for testing->DONE

// still question of length of frame as seems short at 320 here - 880
is more like size (from 120 odd in say_hannah???) - but 550 in playVowel...

// other voices DONE - but should create our own based on klatt parameters

SELX- phoneme and its length?

SELY- voice?

SELZ- pitch

also wormings///

///////TODO:

//fixed bugs in initres, other bugs and new data.py, TODO- port ALL back to ARM

// interpolation/fade is for first fade samples of new frame... DONE but messy with pointers so try to clean up

// also pitch shift - see notes

// use nvp model of running -> larger buffer and schedule frame updates in round style again as in klatt

// variables=pitch, length, voice, phoneme

** 3/2->

vocal fry / crows / syrinx: 

klsyn: The variable 'sk', "skew to alternate periods", is the number
        of 25 microsecond increments to be added to and subtracted
        from successive fundamental period durations in order to
        simulate one aspect of vocal fry, the tendency for alternate
        periods to be more similar in duration than adjacent periods.

crows have single ? tube ?

what are the potential models for crow/raven vocalisation simulation:

- LPC from recordings (collected) or HMM? - base excitation - wavetable excitation
- formant model (excitation source and frequencies?)
- tube/physical models listed: also useful for other work:

1. Kelly-Lochbaum model: https://ccrma.stanford.edu/~jos/pasp/Singing_Kelly_Lochbaum_Vocal_Tract.html -> Perry Cook (refs/code? PRCThesis.pdf)
2. tube resonance model - TRM - see tube.c
3. two mass model - Ishizaka and Flanagan, Fletcher (Ravens)= Fletcher1988.pdf for glottis only
4. waveguide model - transmission line? - perry cook/ lochbaum??? .. tube?
5. APEX model = 2-D vocal tract articulation... same as SC ntube!

how these do differ? see book

/////

generate_xxx(incoming,outgoing,speed,howmany) - as before bug in speed could read overlap////

transition as essential --- SELX/Y/Z - speed of transitions, phoneme point, pitch, shift of formants, specific parameters

** 8/2 work week plan///

- scheduling and generic generator functions - global? how we know where reader in audio.c is for sync, speed also
- breakdown all models and work so far // tests...
- TODOs elaborated eg. test (poss hardware-related) noise on different platforms
- where are we up to with nvp?
- futures: 

articulatory models: APEX?(VocalTractExample? - is all praat - Kelly-Lochbaum): based on KLvocaltract based on http://doc.sccode.org/Classes/NTube.html

/// [[file:~/sc3-plugins/source/SLUGens/SLUGens.cpp::void%20NTube_next(NTube%20*unit,%20int%20inNumSamples)%20{][file:~/sc3-plugins/source/SLUGens/SLUGens.cpp::void NTube_next(NTube *unit, int inNumSamples) {]]

see DAFx-15_submission_32.pdf for differences

= see also  tube.c, vtcalcs/synth

portings/finish/progress?: NVP, voicform in our code comp to/vowgen, simpleklatt, sp0256 - what else from MAME? TSI: [[file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/s14001a.c::TSI%20S14001A%20emulator%20v1.32][file:~/projects/ERD_modules/worm/docs/UME-Core/mame/src/emu/sound/s14001a.c::TSI S14001A emulator v1.32]]

//voicform=file:~/projects/ERD_modules/worm/docs/Csound6.05/Opcodes/fm4op.c (check differences)

vocoder: basic model with ARM FFT, warps

research: HMM->HTK//mage

praat workings

- LPC raven tests as base for LPC acquaintance:

*** first LPC breakdown (also in first section on modes above)

// work on laptop LPC test

- talkie is LPC: notes // LPC/lpc.c

- lpcanalyzer | lpcanalysiss.c :

Linear predictive coding analysis on any arbitrary input signal. The
spectrum of the input signal is modeled, and used to filter the
source. This works most successfully if the source is spectrally flat
to begin with, ie, an impulse train ( Impulse UGen ) or white noise (
WhiteNoise UGen ).

[[file:~/sc3-plugins/source/NCAnalysisUGens/LPCAnalysis.cpp::*%20LPCAnalysis.cpp][file:~/sc3-plugins/source/NCAnalysisUGens/LPCAnalysis.cpp::* LPCAnalysis.cpp]] is there  and LPCsynth: 

[[file:~/sc3-plugins/source/JoshUGens/JoshUGens.cpp::void%20LPCSynth_next_k(LPCSynth%20*unit,%20int%20inNumSamples)][file:~/sc3-plugins/source/JoshUGens/JoshUGens.cpp::void LPCSynth_next_k(LPCSynth *unit, int inNumSamples)]]

- LPC: [[file:~/projects/ERD_modules/worm/docs/Csound6.05/util/lpanal.c::lpanal.c:]]

- lpc dir from SLP book - TODO: run commandline tests from docs/SLP,
  fix mallocs, work in or probably discard as would need lots more
  work

- https://github.com/freedv/codec2/blob/master/src/lpc.c

- JAN/UNIANAL

- docs/lpc-1.0

** 10/2

- lpcana and lpcsyn in: docs/SLP - one small pointer fix and reconstruction is good -> TODO: reduce number of coeffs per frame and subs excitation

tested with var excitations but no luck as we probably need pitch and unvoiced/voiced

** 12/2

- testing lpcana and lpcsyn (in SLP directory) with diff inputs, some changes ..

eg with : sox joe_noise.wav -b 16 -t raw nn gain -32 rate 16000 - as excitation


- what is history of tube.c - from TRM - where? relation to MONET/gnuspeech: http://pages.cpsc.ucalgary.ca/~hill/papers/synthesizer/body.html

gnuspeech is articulatory and tube.c is from softwareTRM by Manzara

see also: [[file:~/projects/ERD_modules/worm/docs/gnuspeech-0.9/Frameworks/Tube/README::#]]

** 17/2

APEX: [[file:~/projects/ERD_modules/worm/docs/APEX-SC-DAFx/UGens]]

for porting ugens are:  (VocaltractArea.cpp - just calcs area for?) === KLVocalTract.cpp

- and how this code relates to tube.c, Ntube sc code, Kelly-Lochbaum?

- *KL code is same as Ntube:* /// [[file:~/sc3-plugins/source/SLUGens/SLUGens.cpp::void%20NTube_next(NTube%20*unit,%20int%20inNumSamples)%20{][file:~/sc3-plugins/source/SLUGens/SLUGens.cpp::void NTube_next(NTube *unit, int inNumSamples) {]]

with 44 tubes specified in: DAFx15.sc

//and from NTube.schelp:

//Loy p347, p358, Kelly Lochbaum junctions used in TubeN
//k= (Z1-Z0)/(Z1+Z0); //Z inversely proportional to A 
//k= ((A0-A1)/(A0A1))/((A0+A1)/(A0A1)) ie similar relation for Z 

difference in perry cook is with nose or?, DRM (Distinctive Region Model)=8 tube sections matching 3 formants

trm-writeup in docs

http://pages.cpsc.ucalgary.ca/~hill/papers/synthesizer/body.html 

//Check further articulatory models:

- other refs: Rosen/DAVO synthesizer (analogue), Liljencrants(1985):  http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/doc/voicebox/glotlf.html
- Flanagan(1975)- example 12 on http://www.festvox.org/history/klatt.html 

not articulatory - Rodet 1984 singing/sines - CMJ_1984 in docs > see also FOF and CHANT

and:

Here is a FOF instrument based loosely on fof.c of Perry Cook and the article "Synthesis of the Singing Voice" by Bennett and Rodet in "Current Directions in Computer Music Research".

(definstrument fofins (beg dur frq amp vib f0 a0 f1 a1 f2 a2 &optional ve ae)
  (let* ((start (floor (* beg *srate*)))
         (end (+ start (floor (* dur *srate*))))
         (ampf (make-env (or ae (list 0 0 25 1 75 1 100 0)) :scaler amp :duration dur))
         (frq0 (hz->radians f0))
         (frq1 (hz->radians f1))
         (frq2 (hz->radians f2))
         (foflen (if (= *srate* 22050) 100 200))
         (vibr (make-oscil 6))
	 (vibenv (make-env (or ve (list 0 1 100 1)) :scaler vib :duration dur))
         (win-freq (/ two-pi foflen))
         (foftab (make-double-float-array foflen))
         (wt0 (make-wave-train :wave foftab :frequency frq)))
    (loop for i from 0 below foflen do
      (setf (aref foftab i) (double-float      
        ;; this is not the pulse shape used by B&R
            (* (+ (* a0 (sin (* i frq0))) 
                  (* a1 (sin (* i frq1))) 
                  (* a2 (sin (* i frq2)))) 
               .5 (- 1.0 (cos (* i win-freq)))))))
    (run
     (loop for i from start below end do
       (outa i (* (env ampf) (wave-train wt0 (* (env vibenv) (oscil vibr)))))))))

(with-sound () (fofins 0 1 270 .2 .001 730 .6 1090 .3 2440 .1)) ; "Ahh"

(with-sound () 
  (fofins 0 4 270 .2 0.005 730 .6 1090 .3 2440 .1 '(0 0 40 0 75 .2 100 1) 
          '(0 0 .5 1 3 .5 10 .2 20 .1 50 .1 60 .2 85 1 100 0))
  (fofins 0 4 (* 6/5 540) .2 0.005 730 .6 1090 .3 2440 .1 '(0 0 40 0 75 .2 100 1) 
          '(0 0 .5 .5 3 .25 6 .1 10 .1 50 .1 60 .2 85 1 100 0))
  (fofins 0 4 135 .2 0.005 730 .6 1090 .3 2440 .1 '(0 0 40 0 75 .2 100 1) 
          '(0 0 1 3 3 1 6 .2 10 .1 50 .1 60 .2 85 1 100 0)))

** TODO: 

- SPASM - tract stuff in [[file:~/projects/ERD_modules/worm/docs/Lua2SC/lua2SC/lua/num]] : MISSING key code
 
The model works with Kelly Lochbaum juntions representing vocal tract and
nose areas as previously done in Perry CookÂ´s SPASM for example.
Glottal excitation is done with a simplified LF-model. (Fant et al)
Model data from "Vocal tract area functions from magnetic resonance imaging"
by Titze et al. 

singer.scm, singer.ins (clm):

[[file:~/collected/fm01/fm01lisp/clm-3/singer.ins::(definstrument%20singer%20(beg%20amp%20data)][file:~/collected/fm01/fm01lisp/clm-3/singer.ins::(definstrument singer (beg amp data)]]

[[file:~/projects/ERD_modules/worm/docs/singer.scm::%3B%3B%3B%20Perry%20Cook's%20physical%20model%20of%20the%20vocal%20tract%20as%20described%20in:][file:~/projects/ERD_modules/worm/docs/singer.scm::;;; Perry Cook's physical model of the vocal tract as described in:]]

clm bird and animals:

[[file:~/collected/fm01/fm01lisp/clm-3/bigbird.ins]]

// (locsig loc i (one-pole fil (* (env amp-env) (oscil s (env gls-env))))))))))

so this is locsig=reverb of one pole (1.0) of amplitude-env of oscil at freq-env

- how SPASM/singer.ins squares with APEX=ntube/tube/lua/what else? - vtsynth/vtcalc

*it is closest to tube.c as ntube/vt... ? are more generic waveguide!*

and lua code: this code is incomplete as doesn't have LF (Liljen/Fant)
glottal stuff nor tract model, but maybe we can make sense of some parameters for our tube.c

- voicform? and tables we have in collated_forms

- compile and test APEX/and/or/ntube? 

ntube/sc examples? [[file:~/sc3-plugins/source/SLUGens/sc/HelpSource/Classes/NTube.schelp]] working...

start to port!

- how to proceed with articulatory crow/worm models -> LPC, tube, formants

= starting with crow source/wavetable as glottal excitation?

Fletcher (1988) - quantitative model... also mentions 200 Hz
fundamental (syrinx frequency), 70 mm elliptical trachea, 6mm to 8mm
diameter, formants 1.4, 2.3, 3.7 and 5 KHz. 

= what we can do with praat and crow voice analysis/simulation?

playing with LPC and tract models extracted from recordings/LPC

can we use LPC co-effecients in lpcsyn?

praat source code for LPC/tube/tract etc.

** 18/2+ TODO:

- looking at LPC:

SLP example are too primitive but good for basics -> try with singlecrow to compare////DONE

lpc55 in lpc-1.0 doesn't compile

UNIANAL in JAN seems to work well - need to dig further in eg. how many frames, size of frame, what is residual energy, excitation:

/* --- LPC analysis defaults --- */

#define DFT_LSEG	160
#define DFT_RSEG	80
#define DFT_WINDOW	1
#define DFT_PREACCENT	9500
#define DFT_LPC_ORDER	10
#define DFT_CENTER	1
#define DFT_MIN_PITCH_SAMPLES	20	/* 400 Hz for Fe=8kHz */
#define DFT_MAX_PITCH_SAMPLES   160	/* 50 Hz for Fe=8kHz */
#define DFT_PITCH_FRAME  320		/* frame length for pitch detection */

residual energy is for whole frame?

excitation: [[file:~/projects/ERD_modules/worm/docs/JAN/UNIANAL/src/synth.c::void%20GeneratePulses%20(float%20fEnergy,%20short%20swPitch,%20short%20swSamplesToDo,][file:~/projects/ERD_modules/worm/docs/JAN/UNIANAL/src/synth.c::void GeneratePulses (float fEnergy, short swPitch, short swSamplesToDo,]]

*- HMM look at - HTK// mage*

*- warps vocoder.*

- elements BLOW to investigate: [[file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/%20Simple%20waveguide%20tube.][file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/ Simple waveguide tube.]] and exciter is quite simple?

** 22/2 notes etc...

- collect and clarify models on paper/from papers

- single excitation-wavetable/noise/envelope/reverb/filter/LPF and so on functions in our code so can easily replicate

- 2 mass model is important for bird song - see praat/speaker -> artsynth (but how much we can modify?)

VOICEBOX is a MATLAB toolbox for speech processing. -> Liljencrants/Fant (LF) vocal source/glottis model - glotlf/gfm_spec_lf

glotlf model working in octave... -> but for our c:

from APEX->LF model ApexSource01 {
	*ar { arg fo=100, invQ=0.1, scale=1.4, mul=1;
		var flow;
		flow = RLPF.ar(Blip.ar(fo, mul: 10000), scale*fo, invQ, invQ/fo); // resonant low pass of BLIP: Band Limited ImPulse generator.
		^HPZ1.ar(flow, mul);   // +6 dB/octave // high pass?
	}
}

- what is two tube SC in SLUgens about?

Physical model; two tube sections with scattering junction inbetween; their relative areas determine k. 

http://doc.sccode.org/Classes/TwoTube.html

- glottal source in tube.c

-  /root/pybombs/src/gr-as/gr36/gr-vocoder/lib/codec2: ???

- whether we need to rethink incoming excitation _and_ voice - look at past notes!

what modes make sense with both? vocoder, lpcanalysis, otherwise just excitation only

- LIST // excitation models? // resonance/tube models

collect code/// and worm.c and parameters in collated_forms and all TODOs

** 23/2

- collect excitation and resonance/tube code

esp. glottal sources: vtsynth, tube.c, SC model above is what?, wavetable, LPC, WHAT ELSE-mass model - where?, LF model !

vtsynth: excitation/whole model seems quite complex

tube.c: simple glottal pulse _or_ sine

SC: BLIP and LPF

- where is LF model: lfgen.c working on - still not working?NOW as compiles 

lfgen.m runs and plots (only when we do run lfgen.m from octave) but why is different for lfgen.c

cross compare epsilon and so on! 

now working with clog (complex) but does this work for ARM?

.... to compile//COMPILES now

*TODO* - pre-calc and test different glottal models, plague algo glottal model

- where is mass model (praat but is not simple): [[file:~/projects/ERD_modules/worm/docs/praat/artsynth/Speaker_to_Delta.cpp::*%20This%20corresponds%20to%20a%20two-mass%20model%20of%20the%20vocal%20cords%20without%20shunt.][file:~/projects/ERD_modules/worm/docs/praat/artsynth/Speaker_to_Delta.cpp::* This corresponds to a two-mass model of the vocal cords without shunt.]]

- collate notes here and from pdfs

- Klatt derivative glottal wave? KLGLOT88, other glottal models in klsyn?

- Rosenberg matlab code:

%Rosenberg Pulse
%this function accepts fundamental frequency of the glottal signal and 
%the sampling frequency in hertz as input and returns one period of 
%the rosenberg pulse at the specified frequency.
%N2 is duty cycle of the pulse, from 0 to 1.
%N1 is the duration of the glottal opening as a fraction of the 
%total pulse, from 0 to 1.
function[gn]=rosenberg(N1,N2,f0,fs)
T=1/f0;     %period in seconds
pulselength=floor(T*fs);    %length of one period of pulse
%select N1 and N2 for duty cycle
N2=floor(pulselength*N2);
N1=floor(N1*N2);
gn=zeros(1,N2);
%calculate pulse samples
for n=1:N1-1
    gn(n)=0.5*(1-cos(pi*(n-1)/N1));
end
for n=N1:N2
    gn(n)=cos(pi*(n-N1)/(N2-N1)/2);
end
gn=[gn zeros(1,(pulselength-N2))];

and:

http://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/45317/versions/5/previews/Callbacks_ideal_vocal_tract_GUI25.m/index.html

http://homepage.univie.ac.at/christian.herbst//python/glottal_air_flow_models_8py.html (also FEM code there)

- compile of lpc/lpcana has issues but we won;t use this anyways

** 24/2

- N.H.Fletcher Bird song- a quantitative model. J. Theo. Biology, 135:455â€“481, 1988 specifically raven model

[- return to Hitchcock/trautonium notes]

- find and condense crow voice pdf and others

- run through all models noted above// code bases:

impulse/excitation: klattsyn/klglot88(?), praat, lfgen to fix and
parametrise, singer/SPASM based on what we have (which
is?-singer.ins/scm), SC example above, LPC, vtsynth(can we re-code?)

// abstract models: 1or2 mass model, LF, impulses/oscillators, wavetable, LPC inverse filtered, Rosenberg-C, R++/Veldhuis

tract/tube/formant: klatt, praat, tube.c/TRM, ntube/sc, lots of formant/bandpass options, LPC, singer/SPASM see above

// models: formant, tube/waveguide/mesh/transmission line, LPC

- Synthesis of Voiced Sounds From a Two-Mass Model of the Vocal
  Cords - Ishizaka and Flanagan

- tested: snd ~/projects/ERD_modules/worm/docs/singer.scm but have to save as wav to play later

** 25/2

- is klglott in klsyn?

/*  Vwave is the differentiated glottal flow waveform, there is a weak
    spectral zero around 800 Hz, magic constants a,b reset pitch-synch */

KLGLOT88 is based on LF and is in KLSYN88 (which nvp is based on apparently)...

and there is flutter in this parwave but also in the klatt/parwave we use:

[[file:~/projects/ERD_modules/worm/docs/www.laps.ufpa.br/aldebaro/classes/04procvoz1sem/Klatts/Klatt-C-Windows-F0flutter/Src/parwave.cpp::file:%20PARWAVE.CPP][file:~/projects/ERD_modules/worm/docs/www.laps.ufpa.br/aldebaro/classes/04procvoz1sem/Klatts/Klatt-C-Windows-F0flutter/Src/parwave.cpp::file: PARWAVE.CPP]]

// g(t) = at2 - bf , for 0 < t < On T0 = 0 , for O<y ^ < t < Tn

so maybe just to extract glottal excitation from parwave and use ... 

- Rosenberg-C, R++/Veldhuis:

Rosenberg: glotros, http://rabbit.eng.miami.edu/students/mfreeman/Digital%20Speech%20Processing/Project2/B_MATLAB.html
 and http://www.cnel.ufl.edu/~xcguo/EEL6586/hw1/Part_B3.html

R++/Veldhuis: ??

- lfgen reverted to pc test code -> write to wav and test different parameters

and write out // parameters from LFinput are: alpham, epsilon - wg and datalength are simple calculations // for use on ARM

but these parameters change with F0 fundamental freq (eg. for vocal fry is 52 < f0 < 94)

or we have lookups for a small range of F0? test this out with lfgen and floats?

** 28/2

??? https://github.com/084/glottis/blob/master/ho2011.m

** 8/3

overviewing - glottal flow models above... 

KLGLOTT88 model (Klatt): the glottal flow is modeled by a third order
polynomial which is possibly smoothed using the low-pass filter
method. There are 4 parameters: A_v, T_0, O_q and TL which is the
attenuation in dB of the low-pass filter at 3000 Hz. Notice that the
asymmetry of the flow cannot be changed and is always: \alpha_m=2/3

from: https://rs2007.limsi.fr/PS_Page_2.html

- where we can find mass model? praat - compile all notes on these
  models with working code for each to test

- where are we at with lfgen? vocal fry settings hang - but not if we
  use double - but how to get round this? revert to lookups as above and test this-partTESTED!

also add noise in lfgen.c - from thesis - also maybe test tract model there to see how sounds?

but why lfgen.m plots look different to thesis? try different parameters

** 9/3

*** ORDERING and work plan: also as one side is new raven work and other is WORM speech synth but both obviously coincide

maybe start raven.org here -> TODO: transfer some of notes and also organise here a bit better

- py-trm has wavetable: [[file:~/projects/ERD_modules/worm/docs/py-trm/gnuspeech/Tube/wavetable.c::/%20Calculates%20the%20initial%20glottal%20pulse%20and%20stores%20it%20in%20the%20wavetable,%20for%20use%20in%20the%20oscillator.][file:~/projects/ERD_modules/worm/docs/py-trm/gnuspeech/Tube/wavetable.c::/ Calculates the initial glottal pulse and stores it in the wavetable, for use in the oscillator.]]

but we have this in our tube.c also here! IGNORE

- lfgen.c - generates something but waveform looks strange/noisy -
  now as little endian and changed way saved now so is unsigned int but still most of wave is negative... WHY?

*** GLOTTAL (or excitation) MODELS:

- Klatt / klsyn - which one and where to look? check nvp also
- tube.c wavetable model
- praat - mass model

- lfgen in progress - still to fix?

- flowgen_shimmer in voice_synth in docs - Fant model WORKING

- http://homepage.univie.ac.at/christian.herbst//python/glottal_air_flow_models_8py_source.html = KLGLOTT88 and Rosenberg

now as *glottalair.py* and writing wav file - seems working -> port to C (also Rosenberg tests in lfgen.c are working)

- others: wavetable, formants a la SINGER/SPASM with two glottal
  oscillators and vibrato -> where? check VOICFORM again, LPC

- plague model (where we find clean code?)

*** TRACHEA MODELS:

- formants/artificial filtering (Klatt)
- vocoder style fixed channels
- tube.c - articulatory
- praat - ??where??
- ntube.c from SC TODO (see also twotube model there)

- Perry Cook/SPASM - digital waveguide ladder filter

[[file:~/projects/ERD_modules/worm/docs/singer.scm::%3B%3B%3B%20Perry%20Cook's%20physical%20model%20of%20the%20vocal%20tract%20as%20described%20in:][file:~/projects/ERD_modules/worm/docs/singer.scm::;;; Perry Cook's physical model of the vocal tract as described in:]] 

- Coker - digital transmission line

- elements BLOW to investigate: [[file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/%20Simple%20waveguide%20tube.][file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/ Simple waveguide tube.]] and exciter is quite simple?


*** other approaches completely

- FOF/CHANT etc...
- VOSIM
- LPC
- HMM?

*** ///////

find synsrc for LF and Rosenberg - can't find

http://www.mattmontag.com/projects-page/academic/speech

NOTES:

    First, the glottal pulse is perturbed with noise to simulate air
    turbulence ("breathiness") at the glottis. Importantly, this noise
    is not applied to the entire glottal signal, but only in the
    positive region where the glottis is open and air flow is present.
    Second, the pitch and amplitude envelope for the speech was
    manipulated to add a small random inflection and natural energy
    decay at the release of vocal stress.  Third, two or three sharp,
    quiet "startup pulses" are inserted at the beginning of the
    glottal pulse train, which represents a subtle glottal fricative
    at the onset of the vowel. This aids in the realism of the vocal
    attack.  Fourth, the signal was low passed with a zero at nyquist
    to reduce high frequency ringing.



http://www.mattmontag.com/projects/speech/speechproduction.m

*** /////

how we can work with these models towards crow voice. pointers:

papers: Fletcher(1988), Smyth and Smith (2002)

** 10/3

thinking on double for raven code and above: -Ofast also as flag

we need gcc 4.9 for doubles to solve bug and this means not using
floating point? arm-eabi...

** 11/3

see raven.org for these days as focus on raven voice

in mage code is hts as main thing - find refs but not for now HTS!

tests on - flowgen_shimmer in shimmer in docs - Fant model WORKING -
see raven/also vowel there is okay filter-wise!

** 14/3

- warps freq shift to look at

shift: [[file:~/projects/ERD_modules/older/eurorack/warps/dsp/modulator.cc::void%20Modulator::ProcessEasterEgg(][file:~/projects/ERD_modules/older/eurorack/warps/dsp/modulator.cc::void Modulator::ProcessEasterEgg(]]


** 29/4---->1/5 UPDATE and RE_APPRAISE

- somehow on our test eurorack version knobs are mixed up so now
  remapped in audio.h but not sure how/why is so - for final annotated
  brd

*** TODO:

LPC tests, wavetable and excitation inputs across modes, just clean up for PARIS thing so works to some degree...

- why tube.c behaves strange: FIXED - think was memory issue for large input_frames array so *we need to watch memory and maybe clean up buffers*

- simple wrapping and round robin style
- where we are with all generators?

- new notes to fill in here esp. on raven/LPC merge - raven wavetable (see braids:

[[file:~/projects/ERD_modules/older/eurorack/braids/digital_oscillator.cc::void%20DigitalOscillator::RenderWavetables(][file:~/projects/ERD_modules/older/eurorack/braids/digital_oscillator.cc::void DigitalOscillator::RenderWavetables(]] )

excitation is raven wavetable with incoming (eg. voice) as LPC filter to apply

(also inverse filtering to output residual could be done seperately)

*but raven will become seperate module*

////

cleaning up but priority is: basic phoneme round for PARIS and cleanups, LPC and excitation for JAPAN

** 25/5 RE_APPRAISE for JUNE 20 release

- how much to port to raven, most needing excitation so LPC but for
  vocoder we need excitation. for raven also add phase vocoder cross
  synthesis

so for RAVEN we have: glottis/wavetable and physical modelling, phase vocoder cross, LPC cross, klanK, all notes on paper and above!

how to resolve vocoder - switched noise/oscillator(pitch) and voice in? or???

- appraise modes in raw so far and what needs to be done besides cleanup/timing/trigger and test issues

- 16 modes we project: 8 basic and 8 wormed of these. port worm
  movements from python code (also degree of randomness - extent of
  movement) - question also if worming should be seperate but is way
  of moving through parameters... but we need to define in each case
  what these are and if is necessary as included...

- so these 8 basic modes are: 1-KLATT (round), 2-VOSIM, 3-vocoder,
  4-SAM-re-check, 5-talkie, 6-filter (XY or formant version), 7+
  formlet?//fof?//lpc//tube/voicform=vowgen/fm4op//parameterised vocoder=voder channels->10 bandpass

change above to ditch X/y and formants

tubes: tube.c, SC tube, tube.cc

- question of speed and munchkins -> deal with pitch rather?

- SP0256 MAME question - contact? S14001 also in mame but again ROM license question...

- where we deal with klatt (and other) parameters?

- question of hardware/noise/inputs - TEST!

- production->solder stencil? also TWO INs question??? for LPC and vocoder only??? probably NOT!

- ADD test pin for audio out//redo zones/vias//re-check all and order!

*** older: 

csound- vowgen is version of voicform but with morphing???? check out, also vibrato and changes to voicform!

http://www.csounds.com/udo/displayOpcode.php?opcode_id=76

and [[file:~/projects/ERD_modules/worm/docs/Csound6.05/Opcodes/fm4op.c]] which is like voices/voicform noted above NOT REALLY 

- HMM look at - HTK// mage

- warps vocoder: [[file:~/projects/ERD_modules/older/eurorack/warps/dsp/vocoder.cc::/%20Vocoder.][file:~/projects/ERD_modules/older/eurorack/warps/dsp/vocoder.cc::/ Vocoder.]]

test/compare all vocoders: mda (with excitation), LADSPA, borboom, own ARM FFT

see also: http://gurzil.livejournal.com/15375.html and pvsvoc in csound code.

- elements BLOW to investigate: [[file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/%20Simple%20waveguide%20tube.][file:~/projects/ERD_modules/older/eurorack/elements/dsp/tube.cc::/ Simple waveguide tube.]] and exciter is quite simple?

** 28/5

reduce PCB and panel to 12HP: in progress

- modes: 1-klatt-constrained also to probability table//2-klatt raw params=nvp or?//3-talkie-how to change
  pitch?//4-SAM?//5-tube//6/7-->filter/formants/formlet/fof/formlet/vowgen/fm/voder
  channels/lpc//8-vocoder

** 30/5

- trim code after mode tests-> trimmed/discard saved... prototype function pointer/function

- look at klatt for break down:

holmes = x elements -> each has xx frames(dur?) -> new_parwave/parwave (nsynth.c) for each frame deals with samples

(so which element we are at, which frame in that element, which sample - new element/new frame...)

- interpolation tests for speed changing

- what/where are klatt raw params: nvp.c which looks a mess, and simpleklatt.c

- other klatt params (basic pitch=F0hz10), length of phoneme list, flutter, skew?)

- run through missing/todo/incomplete code => nvp, what is simpleklatt
  doing, can we use basic phoneme mode 0 klatt code also?, mame code,
  HMM?

- worm simulation/generation - diverging angle?

MAYBE more categories rather than dailies eg. interpol below, klatt, nvp, raven, all collected here - as also started at start to do!

- PLAN - mode test/check // trim // interpolation tests

- still need to define incoming as gate/whatever? excitation/process? TRIGGER PLAN!

** 9/6+

full LPC vocab and new dumps-> catalogue first with D003:

vocab from talkie library:

Vocab_UK_Acorn: 165 words/phrases
Vocab_US_Clock: 35
Vocab_US_Large: 403
Vocab_US_Male: 206
Vocab_US_TI99: 360

TOTALa pprox 1000 /64 knob = say 16 plus female = say 32 banks

+ new vocabs list as: 

WORDEDIT.SDK = female -> D0,D1,D2,D3

D0 is numbers and 5,6,7,8,9, A, ABLE-> CENT //unknown offset and seems end early

D1 - is FINISH -> NINETY same 279 offset

D2 is NO.NOW till SAY - offset? and ends

D3 starts with THIN but has overlaps with above 279 offset

so we have WORDEDIT.SDK (/WORDS) = This allows a menu of preselected words and phrases
to be drawn from.  It also includes the smaller version of the high quality,
prerecorded, female speech that the 800K extended vocabulary disk contains,
but this one runs on a 5.25" floppy.

3.5 po disks has the larger female vocab (D000-D0034) but what we want
is allophones/male also - thing is that these wouldn't have stop bit
so we need really to disassemble to get offsets and lengths?

lpcreader.c goes straight from file top speech with offset

.... echo2LPC LPC from echo2 disk = female 

////

TI99 -> spchrom is same speech data we have no?

parsec rom is phm3112g - offsets around 16992 plus to sort out -
dulled voice so maybe relook at as perhaps start offsets/ends aren't right

(how to line this up)....

lpc_say has vocab we have!

///

for parsec we start offsets from 2 in phm3112g5.bin and follow table on: http://atariage.com/forums/topic/249709-parsec-remake/#entry3456049

but still not so happy with speech - is either 8 bit energy question or try tms5220.cpp code instead...

/// further speech tries on TI99, nada : interested in allophones still and TI sings - tisingarc.txt

** 10/6

- NOTE: testing SELX-Z - does it need to be inverted as 0 is far left
and also all have different end/final for each roughly the same but
less than what it should be?

- TODO: test TRIGGER IN! DONE - tweaking

- in talkie pitch mod is just over/undersampling which we kind of
  have, other mods to do with mapping, repeats etc and speed DONE - but can go further with this!

[- also differences in lattice code there and unwrapped loops]

** 13/6

- stripped/commented code to just test LPC - as also was not programming/running after reset with all code in there...

- starting on generator struct/function pointer using LPC example: interpolation, trigger tests SEEMS to work!

- *lpcanalysis* for SC - windowsize is 32 - can streamline some code
  but not sure to include as has NO parameters so far (what these
  could be? - perhaps for excitation source, and trigger as freezing
  coeffs -  but freeze must be on selx!)

- if in generators we should also write to mainbuffer for later use?

- *lpcforlap.c* prints out array of lpc coeffs from incoming wav file (first option) - uses libsndfile

- lpcannalysis modded for crow coeffs but is a bit static maybe?

TODO *LPC:* need to edit much of new vocab? esp. PARSEC, larger vocab
imported and banks (SELY/Z changes), any low pass for interpolation
code

- *sp0256.c* started... easiest way to test?

TODO: sp0256, [[file:~/mame/src/devices/sound/s14001a.cpp::SSi%20TSI%20S14001A%20speech%20IC%20emulator][file:~/mame/src/devices/sound/s14001a.cpp::SSi TSI
S14001A speech IC emulator]], digitalker, channel vocoder (10 params+
voices/unvoiced+ pitch)

** 14/6

Trying to port rsynth/klatt so runs as generator but crashes and need
to clean up sizes of variables across all rsynth and to speed up
drastically if runs in audio code

- working NOW. watch sizes of stuff!!!

- what is hiss on sample? overrun?

* talkie=LPC/lpc.c TODO

- port and change bendss from talko: [[file:~/projects/ERD_modules/older/euro-modules/Talko/Software/Talko1_2/Talko1_2.cpp]] DONE

- BRING IN larger vocab from:   /root/projects/earthvoice2/Talkie-LPCcode/Talkie/examples

- what we could get from MAME code/roms? - cross-compare co-efficients... still trying to extract speech/allophones code from u25_rom1.bin

Now, here is how speech is encoded:

Frame type  Energy Rpt Pitch   K1    K2   K3   K4   K5   K6   K7  K8  K9  K10 
Voiced      xxxx   0  xxxxxx xxxxx xxxxx xxxx xxxx xxxx xxxx xxxx xxx xxx xxx 
Unvoiced    xxxx   0  000000 xxxxx xxxxx xxxx xxxx 
Repeated    xxxx   1  xxxxxx 
Silence     0000 
Stop code   1111

from: http://www.unige.ch/medecine/nouspikel/ti99/speech.htm

ti99sim which has spchdump segfaults only not with spchrom which is already encoded!

sox and lpc-10

terminal emulator and ALLPHON or allophones (allophone rom should be u25?) 127 allophones

ti99sim: Release/dumpspch --format=hex ~/Downloads/u25_rom1.bin

format=spch

unianal for lpc-10 and check again encoding but what we want is
original allophon code - now have DATABASE from text to speech disk
but somehow can't extract meaningful data...

[[file:~/projects/ERD_modules/worm/docs/ti99sim/src/util/DATABASE::DATABASE%20][file:~/projects/ERD_modules/worm/docs/ti99sim/src/util/DATABASE::DATABASE ]]

and codes from dumpspch don;t match at all R or P etc which we have in vocab 

 - XLAT, SPEAK in machine language?

lpctest for finding lpc codes but as long as they don't concat/// or we need to jump to next byte

have longer look at format of spchrom.bin

convert from lpc-10 via tables in  http://www.unige.ch/medecine/nouspikel/ti99/speech.htm

///

offset 13c3 offset 5059 2 bytes left processing phrase 0

in spchrom is word then 5x,=,,,, then address...

seems like can have REPEAT bit at start with on coeffs>>??

had to NOT reverse bits (and also why we need to reverse - just do for all arrays beforehand!)

...

question of zeroes in vocab after energy=0xf stop bits

now we can parse with lpctest the spchrom fine... need next to use to try and dump codes from disks/cartridges and so on

...

apple II: echo software - now we have some female voice:

is from WORDS_D00 which is expanded from WORDEDIT.SDK but edges are funny and can't GET indexing

?"I can use my TI Text-to-Speech disk along with
software to capture the LPC strings to create new words"

...

some success with parts of:

- is from WORDS_D00 which is expanded from WORDEDIT.SDK (apple II/echo) - female voice (also D001,2 and 3)

- /root/Downloads/TI99/Spch-EdG.Bin which is phonemes perhaps

----

disassembly but need extracted bins... and where code starts:

: ./getfile ../../disks/WORDEDIT.SDK INIT > INIT

: ../../../dcc6502/dcc INIT | less

from: ~/Downloads/TI99/apple/ciderpress/linux

///
 
also nice to print basic straight HOW? - in wine with ciderpress we can

.....

offsets from POINTERS into D00x still not working

...

next/ extract offsets and test! start in POINTERS is at x203... also
just test for one single expression/phrase as seems split up somehow...

start for THIR in pointers is: 06A9 -> points to 004D as address/offset

UNITED STATES = 33(dec) in = 1578dec

how long is average vocab in bytes? say 100 bytes

/// potentially add table offset (c7 style) and other fixed offset

* interpolations

- sinc (Perry Cook): [[file:~/projects/ERD_modules/worm/docs/srconvrt.c]]

- linear interpol and filtering (freq?): http://stackoverflow.com/questions/1125666/how-do-you-do-bicubic-or-other-non-linear-interpolation-of-re-sampled-audio-da

- ominous voice???

and: http://www.rockbox.org/tracker/12223?getfile=24000

go linear!

* SCHEDULE:

- test trigger in and check CVs/DONE - PCB->check/order

- finish LPC vocabulary - refine/clean up

- new sp0256 and vocab // digitalk/s14001a?

- test and evaluate all algos// plan modes

- controls X,Y.Z and mode rundown

- wormcode and how fits with modes// worm movements/// worming in wavetable

- trigger scheme and code - trigger RESTART of algo/generator on IN - TESTED prototype

- generator - code prune/generators-structs for all in audio.c and each mode

- vocoder

- wrap up

///

sp0256 look into as license changed/ also digitalk and S14001 (?)

sp0256 roms: sp0256-al2.ic1 (jupace), sp0256a-al2, sp0256-al2.bin, sp0256b-019.bin, dkspeech.rom

* any hardware notes

latest smaller board is 003

panel is 002
* MODES 13/6_+++

** 0/LPC/TMS5220

- cleanup new vocabulary

- banks of 64 words/phrases SELX/SELY, SELZ is nextperiod

** 1/KLATT

- SELX is phoneme, SELY->pos, SELZ->length and SPEED=dur of each

we need maybe length of sentence, and x,y for phoneme and position (but also stress and dur for each phoneme?)

- added basic pitch shift to test at the moment????

and/or another klatt mode for similar but basic single klatt with more modulation (length of sample also?)

** 2/RAW_KLATT

** 3/SAM

** 4/SP0256 > others

** 5/TUBE

** 6/choose vosim etc - 7- vosim/fof/other etc - ditch formant filters...

** 7/channel vocoder

- 8 or 10 channels, unvoiced, pitch

** 8/vocoder

** 9-15 wormings

- worm movements from paris python -> c

- worm wavetable for excitation with filters
